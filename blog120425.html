<!DOCTYPE HTML>
<html>
<head>
    <link rel="shortcut icon" type="image/png" href="images/Samith Icon.png">
    <title>Building Your Portfolio Website: A Cost-Effective Guide for Beginners - Samith Chimminiyan</title>
    <meta charset="utf-8">
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="assets/css/main.css">
</head>
<body>
    <div class="page-wrap">
			

        <header-main>

			<img src="images/Samith Icon.png" alt="" width="36" height="32">
			<input type="checkbox" id="menu-bar">
			<label for="menu-bar">Menu</label>

			<!-- Nav -->
            <nav class="navbar">
				
				
				<ul>
					
					<li><a href="/" class="active"><span class="icon fa-home"></span></a></li>
					<li><a href="portfolio">Portfolio</a></li>
					<li><a href="blog">Blog</a></li>
					<li>
						<a href="resources">Resources</a>
						
						<ul>
							<li><a href="books">Books</a></li>
							<li><a href="Podcast">Podcast</a></li>
							<li><a href="youtube">Youtube</a></li>
						</ul>
					</li>
					<li><a href="about">About</a></li>
					<li><a href="contact">Contact</a></li>
					<li><a href="services">Services</a></li>
				</ul>
			
			
			
			</nav>
				
		</header-main>		

                    
        
                </div>

            <!-- Blog Section -->
            <section id="blog">
               
                <div class="blog-container">
                <div class="blog-boxfull">
                            <div class="blog-textnew">
                            <div class="blog-titlenew">Selenium Web Scraping Tutorial: Scrape StepStone Job Listings in 20 Minutes</div>
                            <span>12 April 2025/Programming</span>
                            <p>While working on a project, I needed to web scrape data from websites. Before targeting the actual website,
                                 I practiced on a similar one ‚Äî StepStone. Here‚Äôs how I did it, so you can too</p>
                            
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">üîçWhat is Web Scraping?</div>
                                <p>Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. 
                                    Web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser. 
                                    While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. 
                                    It is a form of copying in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, 
                                    for later retrieval or analysis.</p>
                                
                            </div>
                            <div class="blog-textsub">
                                <div class="blog-titlesub">üí°Why Web Scraping?</div>
                                <p>Web Scraping is a cost-efficient way to get the Unique Dataset directly from the website. 
                                    Many advanced paid scrapers and APIs can be used to get the details.
                                     Using Python to scrape data and create your own dataset is incredibly rewarding for any data enthusiast.</p>
                                
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">Which are the methods used for scraping the data by Programmers? Is Selenium popular ?</div>
                                <p>The most popular way of scraping the website is using BeautifulSoup and Requests Libraries writing a python script.
                                     But that won't work on a dynamic website where there is JavaScript-heavy content. Here comes Selenium, which can be used for scraping the JavaScript-heavy websites.
                                     Other widely used Libraries are Playwright and Scrapy preferred for large projects.</p>

                                <p>
                                    Stepstone is mostly Javascript rendered, and we can use Selenium to get the visible contents on the website.
                                     We‚Äôre interested in extracting the salary details of each job and additional relevant features

                                </p>
                                <img src="images/blogs/blog12042501.png" alt="Stepstone Website" title="Stepstone Website" width="850" height="450">

                                <p>When we are searching the keyword and the city or blank. We are getting the details like ‚ÄúJob Title‚Äù, ‚ÄúCompany Name,‚Äù ‚ÄúCity,‚Äù etc. 
                                    We can get more details in a specific tab if we click the Jobs tab. So it's like humans interacting with the website. To make this happen, we need to use Selenium. Selenium gives the website a Human feeling. 
                                    It can be used to click the link, select the drop-down and move through the tabs, etc.
                                </p>
                                
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">What are we looking for?</div>
                                <p>We need to have a csv file with all the details as below</p>
                                <img src="images/blogs/blog12042504.png" alt="csv file" title="csv file" width="850" height="450">
                                <p>The Python script will search all the keywords required by going through each job posting page and 
                                    collecting all the required details in that tab and then closing each tab without any human interaction.</p>
                                
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">üß∞ Tools and Libraries</div>
                                <ul>
                                    <li>Working knowledge of Python</li>
                                    <li>Python Version 3+</li>
                                    <li>PyCharm / VSCode / Jupyter Notebook installed</li>
                                    <li>Basic knowledge of HTML</li>
                                    <li>Some knowledge of XPath</li>
                                    <li>Selenium installed</li>
                                    <li>Chrome installed</li>
                                  </ul>
                             
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">The Core Principle of Web Scraping</div>
                                <p>It is quite simple. Let‚Äôs assume you have seen some text on the webpage and you would like to scrape it.
                                     Elements on a web page reside in a hierarchy. 
                                    You just need to tell your code the ‚Äúaddress‚Äù of the element within that hierarchy.</p>
                                
                                <p>Let's check the Salary Range on the page. Right-click the desired item and click the inspect option to see the HTML code. 
                                    On the left-hand top, there is an arrow mark indicating the inspect of the element. 
                                    Just click and click on the desired element to see the code highlighted.</p>

                                    <img src="images/blogs/blog12042502.png" alt="Inspecting the web page" title="Inspecting the web page" width="850" height="450">

                                    <img src="images/blogs/blog12042503.png" alt="checking the selectors from Web page" title="checking the selectors from Web page" width="850" height="450">

                                <p>
                                    We are not bothered about the full code. 
                                    We just need to see which are the selectors that we can choose and retrieve the text.
                                     Here we have XPATH, and using XPATH, we can retrieve the text.

                                </p>

                                <pre><code>
                                    try:
                                        salary_range = driver.find_element(By.XPATH,'//span[@data-at="salary-range"]').text
                                    except NoSuchElementException:
                                        salary_range = -1
                                </code></pre>
                                <p>if you understand what we‚Äôre doing here. 
                                    It means that you can easily scrape almost any website you like. 
                                    There are many selectors that we can use similar to XPATH, like ID, CSS_SELECTOR, CLASS_NAME, etc

                                </p>

                                <p>
                                    Some fields will not always be available on the website.
                                     For Example, the Salary range, so we need to go for exception and give a fixed value.
                                </p>
                                
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">The Code</div>
                                <p>You can download the code from the below links.</p>
                                <a href="https://github.com/samithcsachi/PythonProjects/blob/main/Stepstone%20Web%20Scrapper/stepstone_scrapper.py" target="_blank">
                                    Github
                                </a>
                                <a href="https://www.kaggle.com/code/samithsachidanandan/stepstone-web-scrapper" target="_blank">
                                    Kaggle
                                </a>
                                <p>If you are able to understand the above details and if you have basic Python knowledge, you can easily go through the code with comments. 
                                    Now, I shall explain to you the issues I faced during coding.</p>
                                
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">üîêHandling Sign-in Issue</div>
                                <p>If you are running the code as it is, then you need to create a .env file where you need to save a valid email and password registered with stepstone. 
                                    I have created an email ID and password for this purpose so that I can log in. Then, the question arises as to why I need to log in. I need to log in so that I can get the salary range details.
                                     If you don‚Äôt want a Salary range, then you can skip that step where logging is enabled. Below is the code for logging in.</p>
                                <pre><code>
                                    # Signing in for getting the Salary Info. Can skip this step if salary info is not required.
                                    driver.find_element(By.XPATH, "//div[normalize-space()='Sign in']").click()

                                    driver.find_element(By.XPATH, "//span[@class='hf-provider-gxei9d'][normalize-space()='Sign in']").click()





                                    username_field = driver.find_element(By.CLASS_NAME, "login-registration-provider-1wuqtqx")
                                    password_field = driver.find_element(By.CLASS_NAME, "login-registration-provider-1g1vgpu")

                                    username_field.send_keys(username)
                                    password_field.send_keys(password)

                                    login_button = driver.find_element(By.CLASS_NAME, "login-registration-provider-1k4ab3x")

                                    assert not  login_button.get_attribute("disabled")
                                    login_button.click()

                                    time.sleep(random.uniform(2, 5))

                                </code></pre>                                                            
                                
                            </div>
                            <div class="blog-textsub">
                                <div class="blog-titlesub">üç™Accepting Cookies</div>
                                <p>Whenever you visit the site, you need to accept the cookies. 
                                    So have accepted the cookies using the below code.</p>
                                <pre><code>
                                    Accepting the Cookies File
                                    try:
                                        driver.find_element(By.ID, "ccmgt_explicit_accept").click()
                                    except NoSuchElementException:
                                        pass

                                </code></pre>
                                
                                
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">üß±Dealing with Akamai Error</div>
                                <p>An Akamai error typically refers to an issue encountered while using Akamai‚Äôs content delivery network (CDN) or web security services. 
                                    Akamai is a company that provides services like content caching, website acceleration, cloud security, and DDoS protection for websites and apps.</p>

                                <p>
                                    Companies don‚Äôt like people to scrap their websites, so they are using different techniques to block the user. This is one of them.

                                </p>
                                <p>
                                    I have used the code below to bypass the error. Also have used a few auto refresh and time sleep with random value to bypass the detention. Not sure which one helped.

                                </p>
                                <pre><code>
                                    # Checking for Akamai Edge Error and Skipping it.
                                    if "Reference #" in driver.page_source and "edgesuite.net" in driver.current_url:
                                        print("Akamai Edge error detected. Retrying once after delay...")
                                        time.sleep(2)
                                        driver.refresh()
                                        WebDriverWait(driver, 10).until(
                                            lambda d: "Reference #" not in d.page_source or "edgesuite.net" not in d.current_url)
                                        time.sleep(random.uniform(2, 5))

                                        if "Reference #" in driver.page_source:
                                            print("Persistent Akamai error. Skipping this session.")
                                            if len(driver.window_handles) > 1:
                                                driver.close()
                                                driver.switch_to.window(driver.window_handles[0])
                                            else:
                                                print("No secondary tab to close. Continuing.")

                                </code></pre>
                                
                                
                            </div>
                            <div class="blog-textsub">
                                <div class="blog-titlesub">‚ö†Ô∏è Important Notes</div>
                                <ul>
                                    <li>Not recommended for large-scale scraping</li>
                                    <li>Respect website‚Äôs Terms of Use</li>
                                    <li>Use delays to mimic human behavior</li>
                                  
                                  </ul>
                             
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">‚úÖConclusion</div>
                                <p>Even though there API for scraping the website, it is a best practice to try Python web scraping using Selenium.
                                     Using Python, we will have better control over what is to be scraped. Also, we don‚Äôt need to pay for the API‚Äôs. 
                                     Since the companies are heavily checking on automation bots and blocking it frequently.
                                    This method is not suggested for creating large datasets.</p>
                               
                                
                                
                            </div>

                            <div class="blog-textsub">
                                <div class="blog-titlesub">üßæEND</div>
                                <p>Hope you enjoyed reading and have learned something from this post. Happy coding.</p>
                                <p>üöÄ Cheers to Your Learning Journey!</p>
                               
                                
                                
                            </div>











                                
                </div>     
            </div>
            </section>

            <!-- Copyright -->
            <div class="copyright">
                <ul class="icons"><li><a href="https://github.com/samithcsachi" class="icon fa-github"target="_blank"><span class="label">Github</span></a></li>
                    <li>
                        <a href="https://public.tableau.com/app/profile/samith.chimminiyan/vizzes"target="_blank">
                            <img src="images/tableau.png" alt="" width="36" height="32">
                            
                        </a>
                    </li>
                    <li>
                        <a href="https://www.kaggle.com/samithsachidanandan"target="_blank">
                            <img src="images/Kaggle.png" alt="" width="36" height="32">
                            
                        </a>
                    </li>
                    <li><a href="https://www.linkedin.com/in/samithchimminiyan/" class="icon fa-linkedin"target="_blank"><span class="label">Linkedin</span></a></li>
                </ul>
                
                <a href="#">Copyright ¬© Samith Chimminiyan 2024-2025</a><br>
                <a href="/">Privacy Policy</a>
                <a href="/">Terms of Use</a>
                
                
            </div>
        </section>

        <!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.poptrox.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/skel.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
    </div><!-- .page-wrap -->
</body>
</html>
